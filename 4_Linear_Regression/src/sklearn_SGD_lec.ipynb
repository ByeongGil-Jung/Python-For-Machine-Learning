{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Stochastic Gradient Descent '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Stochastic Gradient Descent \"\"\"\n",
    "# ** Stochastic Gradient Descent 마지막 부분에 4 가지 GD 방법에 대한 비교 및 차이가 잘 나와있다 !!\n",
    "\n",
    "# >> 실제로는 Gradient Descent 보다 SGD (Stochastic Gradient Descent) 를 더 많이 사용한다.\n",
    "# '확률적인 경사 하강법' 이라는 의미를 갖고 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 기존의 GD 는 확장된 개념으로 Full-batch Gradient Descent 를 사용 '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 기존의 GD 는 확장된 개념으로 Full-batch Gradient Descent 를 사용 \"\"\"\n",
    "\n",
    "# 한 점이 아닌, 한번에 여러 개의 점의 gradient 를 업데이트 하는 방법이다.\n",
    "# >> 이를 Full-batch Gradient Descent 라고 한다.\n",
    "\n",
    "# < 장점 >\n",
    "# - GD 가 1 개의 데이터를 기준으로 미분하는 것과는 달리, 동시에 여러 데이터를 미분한다.\n",
    "# - 앞으로 일반적으로 GD = (full) batch GD 라고 가정한다.\n",
    "# - 모든 데이터 셋으로 학습\n",
    "# - 업데이트 감소 -> 계산상 속도의 효율성을 높임\n",
    "# - 안정적인 Cost 함수 수렴\n",
    "\n",
    "# < 단점 >\n",
    "# - 지역 최적화 가능 (전체 data 를 한번에 같이 넣기 때문)\n",
    "# - 메모리 문제 (-> 수십 억개의 데이터를 한번에 업데이트 하기엔 무리가 있음)\n",
    "# - 대규모 data set (-> model / parameter 업데이트가 느려짐)\n",
    "\n",
    "# => 즉, 메모리 문제 등으로 딥러닝, 초대규모 data set 에선 사용하기 힘들다.\n",
    "# => 이를 보완할 방법으로 SGD 사용 (특히 mini-batch SGD 는 제일 많이 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' SGD 원리 '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" SGD 원리 \"\"\"\n",
    "\n",
    "# - GD 처럼 차례대로 한 점씩 접근하는 것이 아닌, \n",
    "#   한 번에 랜덤한 여러 점에서 접근한다.\n",
    "\n",
    "# > 원래 용도는 data set 에서 random 하게 training sample 을 뽑은 후 학습할 때 사용한다.\n",
    "\n",
    "# < Pseudo Code >\n",
    "# - data (X) 를 넣기 전에 random shuffle.\n",
    "# - shuffle 한 X 를 한개 한개씩 불러와서 update\n",
    "#\n",
    "# procedure SGD:\n",
    "#     shuffle(X)\n",
    "#     for i in number of X:\n",
    "#         theta_j := (theta_j - a * (y^(i) - y(i)) * x_j(i))\n",
    "\n",
    "# < 장점 >\n",
    "# - 일부 문제에 대해 GD 보다 더 빨리 수렴\n",
    "# - 지역 최적화 회피\n",
    "\n",
    "# < 단점 >\n",
    "# - 빈번한 업데이트로 인해 전체적인 시간이 좀 오래 걸림\n",
    "# - 대용량 데이터 작업 시 시간이 오래 걸림\n",
    "# - 더 이상 cost 가 줄어들지 않는 시점의 발견이 어려움\n",
    "\n",
    "# => 이를 보완하기 위해 'Mini-batch (Stochastic) Gradient Descent' 개념이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mini-batch (Stochastic) Gradient Descent '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Mini-batch (Stochastic) Gradient Descent \"\"\"\n",
    "\n",
    "# 처리할 데이터의 영역을 분할하여 연산을 수행한다.\n",
    "\n",
    "# - 한 번에 일정량의 데이터를 랜덤하게 뽑아서 학습\n",
    "# - SGD 와 Batch GD 를 혼합한 기법\n",
    "# - 가장 일반적으로 많이 쓰이는 기법\n",
    "#   (딥러닝의 optimization 된 알고리즘의 기본이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Epoch & Batch-size '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Epoch & Batch-size \"\"\"\n",
    "\n",
    "# - Epoch ?\n",
    "#   :: 전체 데이터가 Training data 에 들어가는 횟수 (들어갈 때 카운팅)\n",
    "# - Full-batch 를 n 번 실행하면 n epoch\n",
    "# - Batch-size ?\n",
    "#   :: 한 번에 학습되는(update 되는) 데이터의 갯수\n",
    "\n",
    "# ex) 총 5,120 개의 Training data 에 512 batch-size 면\n",
    "#     몇 번 학습을 해야 1 epoch 가 되는가 ?\n",
    "# ans) 10 번\n",
    "\n",
    "# < Pseudo Code >\n",
    "# procedure Mini_Batch_SGD:\n",
    "#     shuffle(X)\n",
    "#     BS <- Batch Size\n",
    "#     // NB <- Number of Batches (== 1 epoch 이 되기 위해 도는 횟수)\n",
    "#     NB <- len(X)//BS\n",
    "#     for i in NB:\n",
    "#         theta_j := theta_j- a * sum(y^(k) - y(k), from: k = i*BS, to: (i+1)*BS) * x_j(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" SGD 구현 \"\"\"\n",
    "\n",
    "# 여러가지 고려사항이 있다.\n",
    "# 1. Hyper Parameter (사용자 입력 인자) 를 특히 신경써야 한다.\n",
    "#    (iteration 을 몇 번 해야 할지, \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def GD_SGD(X, epochs, is_SGD):\n",
    "    for epoch in range(epochs):  # 전체 epoch 이 iteration 되는 횟수\n",
    "        X_copy = np.copy(X)\n",
    "        if is_SGD:  # SGD 여부 -> SGD 일 경우 shuffle\n",
    "            np.random.shuffle(X_copy)  # data shuffling\n",
    "        batch = len(X_copy)  # 한 번에 처리하는 BATCH_SIZE\n",
    "        for batch_count in range(batch):  # 한 번 온전히 돌면 1 epoch 이다.\n",
    "            # BATCH_SIZE 크기 만큼 X_batch 생성\n",
    "            X_batch = np.copy(X_copy[batch_count * batch: (batch_count + 1) * batch])\n",
    "        print(\"Number of epoch : %d\" % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.linear_model' has no attribute 'LinearRegressionGD'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-35469af6ffa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# eta0 == running rate, epochs == iteration 횟수, batch_size == BATCH_SIZE, shuffle == shuffle 여부\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgd_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegressionGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mfbgd_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegressionGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msgd_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegressionGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.linear_model' has no attribute 'LinearRegressionGD'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 예제에선 LinearRegressionGD 를 썼는데 어딨는지 모르겠다 ...\n",
    "# LinearRegressionGD 는 위의 알고리즘을 구체화 한 것이라고 한다.\n",
    "\n",
    "# 일단 개념을 잡기 위해 적어보겠다.\n",
    "# (하나의 함수로 모든 GD 를 구현 가능하다)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# eta0 == running rate, epochs == iteration 횟수, batch_size == BATCH_SIZE, shuffle == shuffle 여부\n",
    "gd_lr = linear_model.LinearRegressionGD(eta0=0.001, epoches=10000, batch_size=1, shuffle=False)\n",
    "fbgd_lr = linear_model.LinearRegressionGD(eta0=0.001, epoches=10000, batch_size=len(X), shuffle=False)\n",
    "sgd_lr = linear_model.LinearRegressionGD(eta0=0.001, epochs=10000, batch_size=1, shuffle=True)\n",
    "msgd_lr = linear_model.LinearRegressionGD(eta0=0.001, epochs=10000, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 성능 비교 '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 성능 비교 \"\"\"\n",
    "\n",
    "# MSGD 는 떨림이 심하다. (랜덤하게 data 를 input 하기 때문)\n",
    "# GD, FGD 는 전체 data 가 들어가기 떄문에 안정적으로 수렴한다.\n",
    "\n",
    "# 실제로 시간 및 속도를 비교해보면,\n",
    "# 한 점씩 update 하는 GD 와 SGD 가 비교적 오래 걸리고, (약 1.37 s)\n",
    "# 모든 데이터를 update 하는 FGD 가 제일 빠르다. (약 3.74 ms)\n",
    "# MSGD 는 두번째로 빠르다 (약 122 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Learning-rate Decay '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Learning-rate Decay \"\"\"\n",
    "\n",
    "# rate 수치가 크다면 수렴하지 못하고 계속 왕복하게 된다.\n",
    "# >> 즉, rate 수치를 시간이 지날수록 점점 조금씩 줄여주면 된다 !\n",
    "#    이를 Learning-rate decay 라고 한다.\n",
    "#    (SGD 에선 필수적으로 사용해야 한다 !)\n",
    "\n",
    "# Learning-rate ??\n",
    "# - 일정한 주기로 Learning rate 를 감소시키는 방법\n",
    "# - 특정 epoch 마다 Learning rate 를 감소\n",
    "#   (self._eta0 = self.eta0 * self._learning_rate_decay)\n",
    "# - Hyper-parameter 설정의 어려움\n",
    "\n",
    "# - 지수 감소 : a = a0 * e^(-k*t)\n",
    "# - 1/t 감소 : a = a(0) / (1 + k*t)\n",
    "\n",
    "# Learning-rate 종료 조건 ??\n",
    "# - SGD 과정에서 특정 값 이하로 cost function 이 줄어들지 않을 경우 GD 를 멈추는 방법\n",
    "# - 성능이 좋아지지 않는(필요 없는) 연산을 방지함\n",
    "# - 종료조건을 설정\n",
    "#   (- tol > loss - previous_loss)\n",
    "# - tol 은 hyper-parameter 로 사람이 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Overfitting '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Overfitting \"\"\"\n",
    "# SGD 와 같은 방식의 가장 큰 문제점은 Overfitting 이 발생할 수 있다는 것이다.\n",
    "\n",
    "# Overfitting ?\n",
    "#  :: 도출된 모델이 Training data 에만 최적화 되어 있어서, 새로운 데이터의 예측이 힘든 상황\n",
    "# 즉, 모델은 generalization 이 중요하다. -> 평범해야 한다.\n",
    "\n",
    "# 신조 : 보다 적은 수의 논리(parameter)로 설명이 가능한 경우, 만은 수의 논리(parameter)를 세우지 말라\n",
    "#   ( - Occam's razor)\n",
    "# >> 즉, 되도록 적은 parameter 로 모델을 만들 것.\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# < Bias - Variance Trade-off >\n",
    "#  1. High Bias\n",
    "#   - 원래 모델과 많이 떨어짐\n",
    "#   - 잘못된 데이터만 계속 학습함\n",
    "#    >> 잘못된 weight 만 update\n",
    "\n",
    "#  2. High Variance\n",
    "#   - 모든 데이터에 민감하게 학습\n",
    "#   - Error 를 고려하지 않음\n",
    "#    >> 모든 weight 가 update\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "# < Overfitting 을 극복하는 방법 ? >\n",
    "\n",
    "# - 더 많은 data 를 활용한다. (data 의 갯수를 늘린다.) -> 제일 좋은 방법\n",
    "# - feature 의 갯수를 줄인다.\n",
    "# - 적절히 parameter 를 선정한다.\n",
    "#\n",
    "# - Regularization (매우 중요 !!)\n",
    "#   (수식은 강의 뒷부분 참조 ... )\n",
    "#   >> 식 맨 뒤에 (+ 1000 * theta_1) 등의 패널티를 줘서 theta 값이 많이 안늘어나게 하는 방법이다.\n",
    "#      (cost function 의 수치를 높인다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Regularization '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Regularization \"\"\"\n",
    "# 자세한 식과 그래프는 강의 참조 ...\n",
    "# norm ? \n",
    "#  >> 벡터의 길이 혹은 크기를 측정하는 방법\n",
    "\n",
    "# < L2 Regularization >\n",
    "# - 기존 cost function 에 L2(norm) penalty term 을 추가\n",
    "# (L2 ? \n",
    "#   >> euclidean distance (원점에서 벡터 좌표까지의 거리 - 피타고라스 정리를 이용함))\n",
    "#   >> 원의 접점과의 거리로 구함\n",
    "\n",
    "# < L1 Regularization >\n",
    "# - 기존 cost function 에 L1(norm) penalty term 을 추가\n",
    "# - L2 와 달리, 절대값을 이용하여 penalty 를 주는 방법. (L2 보단 penalty 가 적다.)\n",
    "# (L1 ?\n",
    "#   >> manhattan distance (원점에서 벡터 좌표까지의 거리))\n",
    "#   >> 마름모의 절편과의 접점을 통해 구함. (즉, 여러 점에서 만날 수 있다.)\n",
    "#      즉, L1 에서 weight 값이 0 이 되는 값은, 중요하지 않은 weight 값 임을 알 수 있다.\n",
    "\n",
    "\n",
    "# => L2 가 L1 보다 더 stable 하다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
